{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction to Sciline\n",
    "\n",
    "<h4><i>Data processing workflow management tool.</i></h4>\n",
    "\n",
    "<h3><a href=\"https://scipp.github.io/sciline/\">scipp.github.io/sciline/</a></h3>\n",
    "\n",
    "<br>\n",
    "\n",
    "Sciline is an open-source library developed by ESS for managing and visualizing data processing workflows (sometimes called \"pipelines\").\n",
    "\n",
    "It defines workflows as directed acyclic graphs (DAGs) where the nodes are inputs, intermediate results, or final results, and edges are dependencies between the nodes.\n",
    "\n",
    "This has some benefits:\n",
    "\n",
    "- Any (named) intermediate result in the pipeline can be computed.\n",
    "- The dependencies between intermediate results can be visualized.\n",
    "- Implementations of intermediate result can be replaced.\n",
    "- Results that are expensive to compute can be cached.\n",
    "- Certainty that the computed result has not been corrupted by running jupyter cells out of order.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "A Sciline **workflow** (or \"pipeline\") is defined by a set of transformations or **providers** that specify what inputs are needed to compute one specific output quantity.\n",
    "\n",
    "The input and output quantities of the providers are called **domain types**.\n",
    "\n",
    "A provider is a python function with type annotations:\n",
    "\n",
    "```python\n",
    "# Example provider\n",
    "def load_run(\n",
    "    run_number: RunNumber,\n",
    "    proposal_number: ProposalNumber,\n",
    "    data_dir_path: DataPath,\n",
    ") -> LoadedNexusData:\n",
    "\n",
    "    filename = f'{proposal_number}_{run_number:06d}.hdf'\n",
    "    path = os.path.join(data_dir_path, filename)\n",
    "    \n",
    "    with snx.File(path) as f:\n",
    "        data = f[()]\n",
    "        \n",
    "    return data\n",
    "```\n",
    "\n",
    "In the above example, to compute the `LoadedNexusData` quantity the `RunNumber`, `ProposalNumber` and the `DataPath` quantities are needed.\n",
    "\n",
    "`LoadedNexusData`, `RunNumber`, `ProposalNumber` and `DataPath` are \"domain types\".\n",
    "\n",
    "The domain types are the nodes in the workflow graph, and they represent the inputs, intermediate results, or final results of the workflow.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Inputs, intermediate results, and final results\n",
    "\n",
    "A typical data reduction workflow has some \"**Inputs**\", some \"**Intermediate results**\" and some \"**Final results**\".\n",
    "\n",
    "Sciline does not distinguish between those, but it is useful to make a loose distinction:\n",
    "\n",
    "**Inputs** are typically:\n",
    "\n",
    "- The name of one or more NeXus files.\n",
    "- Parameters defining a region of interest (ROI),\n",
    "  - for example the wavelength range.\n",
    "- The number of histogram bins.\n",
    "\n",
    "**Intermediate results** are typically:\n",
    "\n",
    "- List of events with associated coordinates, masks, and weights.\n",
    "  - \"Coordinates\" such as wavelength, scattering angle, etc.\n",
    "- Monitor wavelength histogram.\n",
    "- Various calibration factors that are computed or loaded from file.\n",
    "\n",
    "**Final results** are typically:\n",
    "\n",
    "- Curve describing the scattering cross section $S(Q)$ as a function of momentum transfer (SANS).\n",
    "- List of peaks and associated intensities (diffraction).\n",
    "- Etc.\n",
    "\n",
    "![Sciline graph example](sciline-graph-example.svg \"Illustration of a Sciline workflow graph\")\n",
    "\n",
    "### How does Sciline know how to build the graph?\n",
    "\n",
    "Each domain type is **unique**, and given a list of all functions to be used in the workflow,\n",
    "Sciline can figure out how to connect the nodes in the graph.\n",
    "\n",
    "Think of it like puzzle pieces that fit into each other:\n",
    "\n",
    "<img src=\"sciline-puzzle-1.svg\" width=\"600\">\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "<img src=\"sciline-puzzle-2.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "### Creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import NewType\n",
    "\n",
    "import sciline as sl\n",
    "import scipp as sc\n",
    "\n",
    "from scippneutron.conversion.graph.beamline import beamline\n",
    "from scippneutron.conversion.graph.tof import elastic\n",
    "\n",
    "import sans_utils as utils\n",
    "\n",
    "\n",
    "# Start by defining the domain types\n",
    "# - quantities representing input parameters, intermediate results and the final results of the pipeline.\n",
    "\n",
    "Foldername = NewType(\"Foldername\", str)\n",
    "\"\"\"Folder name for measurements.\"\"\"\n",
    "\n",
    "RawData = NewType(\"RawData\", sc.DataArray)\n",
    "\"\"\"Raw loaded data.\"\"\"\n",
    "\n",
    "CoordTransformGraph = NewType(\"CoordTransformGraph\", dict)\n",
    "\"\"\"Graph describing coordinate transformations.\"\"\"\n",
    "\n",
    "WavelengthData = NewType(\"WavelengthData\", sc.DataArray)\n",
    "\"\"\"Data with wavelength coordinate.\"\"\"\n",
    "\n",
    "QData = NewType(\"Qdata\", sc.DataArray)\n",
    "\"\"\"Data with Q coordinate.\"\"\"\n",
    "\n",
    "QBins = NewType(\"QBins\", sc.Variable)\n",
    "\n",
    "QHistogram = NewType(\"QHistogram\", sc.DataArray)\n",
    "\"\"\"Data histogrammed in Q bins.\"\"\"\n",
    "\n",
    "\n",
    "def load(folder: Foldername) -> RawData:\n",
    "    \"\"\"Load raw data from file\"\"\"\n",
    "    return utils.load_sans(folder)\n",
    "\n",
    "\n",
    "def to_wavelength(\n",
    "    data: RawData, graph: CoordTransformGraph\n",
    ") -> WavelengthData:\n",
    "    \"\"\"Compute wavelength for events\"\"\"\n",
    "    return data.transform_coords(\"wavelength\", graph=graph)\n",
    "\n",
    "\n",
    "def to_Q(data: WavelengthData, graph: CoordTransformGraph) -> QData:\n",
    "    \"\"\"Compute Q for events\"\"\"\n",
    "    return data.transform_coords(\"Q\", graph=graph)\n",
    "\n",
    "\n",
    "def to_histogram(events: QData, qbins: QBins) -> QHistogram:\n",
    "    \"\"\"Histogram data in Q bins\"\"\"\n",
    "    return events.hist(Q=qbins)\n",
    "\n",
    "\n",
    "graph = {**beamline(scatter=True), **elastic(\"tof\")}\n",
    "\n",
    "workflow = sl.Pipeline(\n",
    "    # List the providers that make up the workflow.\n",
    "    (load, to_wavelength, to_Q, to_histogram),\n",
    "    # Optionally, assign values to domain types.\n",
    "    params={CoordTransformGraph: graph}\n",
    ")\n",
    "\n",
    "workflow.visualize(graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Some domain types are visualized in red color and with dashed border, those are the domain types that **lack a definition**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[QBins] = sc.linspace(\"Q\", 5.0e-3, 0.19, 201, unit=\"1/angstrom\")\n",
    "workflow[Foldername] = utils.fetch_data(\"3-mcstas/SANS_with_sample_many_neutrons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.visualize(graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Computing quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_hist = workflow.compute(QHistogram)\n",
    "q_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_data = workflow.compute(WavelengthData)\n",
    "wavelength_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_results = workflow.compute((WavelengthData, QHistogram))\n",
    "two_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_results[QHistogram]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Replace intermediate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength_data = wavelength_data.assign_masks(\n",
    "    wavelength_too_high = wavelength_data.coords['wavelength'] >= sc.scalar(6.5, unit='angstrom')\n",
    ")\n",
    "workflow[WavelengthData] = wavelength_data\n",
    "\n",
    "workflow.visualize(graph_attr={'rankdir': 'LR'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Common errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = sl.Pipeline(\n",
    "    # Missing to_Q provider!\n",
    "    (load, to_wavelength, to_histogram),\n",
    ")\n",
    "# Graph is disconnected\n",
    "workflow.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line to see the exception\n",
    "#workflow.compute(QHistogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_to_histogram(events: QData, qbins: QBins) -> QHistogram:\n",
    "    \"\"\"Histogram data in Q bins\"\"\"\n",
    "    # Wrong coordinate name!\n",
    "    return events.hist(q=qbins)\n",
    "\n",
    "workflow = sl.Pipeline(\n",
    "    (load, to_wavelength, to_Q, bad_to_histogram,),\n",
    ")\n",
    "workflow[Foldername] = utils.fetch_data(\"3-mcstas/SANS_with_sample_many_neutrons\")\n",
    "workflow[CoordTransformGraph] = graph\n",
    "workflow[QBins] = 200\n",
    "\n",
    "# Uncomment the next line to see the exception\n",
    "#workflow.compute(QHistogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Generic domain types\n",
    "\n",
    "Sometimes we want to replicate parts of a workflow and apply it to a different input.\n",
    "\n",
    "A typical case is when we have a sample measurement and want to correct it by a background measurement.\n",
    "\n",
    "In that case many of the processing steps are identical, but ultimately we want to subtract the background measurement from the sample measurement.\n",
    "\n",
    "Generic domain types lets us define domain types that represent \"Y of the X\" such as:\n",
    "- `Filename[Background]`: Filename of the background run.\n",
    "- `QHistogram[Sample]`: The Q-histogram of the sample run.\n",
    "- `QHistogram[Background]`: The Q-histogram of the background run.\n",
    "- etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Example: Generic domain types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType, TypeVar\n",
    "import sciline\n",
    "\n",
    "_fake_filesystem = {\n",
    "    'file102.txt': [1, 2, float('nan'), 3],\n",
    "    'file103.txt': [1, 2, 3, 4],\n",
    "    'file104.txt': [1, 2, 3, 4, 5],\n",
    "    'file105.txt': [1, 2, 3],\n",
    "    'background.txt': [0.1, 0.1],\n",
    "}\n",
    "\n",
    "# Define concrete RunType values we will use.\n",
    "Sample = NewType('Sample', int)\n",
    "Background = NewType('Background', int)\n",
    "\n",
    "# Define generic domain types\n",
    "RunType = TypeVar('RunType', Sample, Background)\n",
    "\n",
    "# sciline.Scope makes Filename a \"generic\" domain type that depends on RunType.\n",
    "class Filename(sciline.Scope[RunType, str], str): ...\n",
    "\n",
    "\n",
    "class RawData(sciline.Scope[RunType, dict], dict): ...\n",
    "\n",
    "\n",
    "class CleanedData(sciline.Scope[RunType, list], list): ...\n",
    "\n",
    "\n",
    "# Define normal domain types\n",
    "ScaleFactor = NewType('ScaleFactor', float)\n",
    "BackgroundSubtractedData = NewType('BackgroundSubtractedData', list)\n",
    "Result = NewType('Result', float)\n",
    "\n",
    "\n",
    "def load(filename: Filename[RunType]) -> RawData[RunType]:\n",
    "    \"\"\"Load the data from the filename.\"\"\"\n",
    "    data = _fake_filesystem[filename]\n",
    "    return {'data': data, 'meta': {'filename': filename}}\n",
    "\n",
    "\n",
    "def clean(raw_data: RawData[RunType]) -> CleanedData[RunType]:\n",
    "    \"\"\"Clean the data, removing NaNs.\"\"\"\n",
    "    import math\n",
    "    return [x for x in raw_data['data'] if not math.isnan(x)]\n",
    "\n",
    "\n",
    "def subtract_background(\n",
    "    data: CleanedData[Sample], background: CleanedData[Background]\n",
    ") -> BackgroundSubtractedData:\n",
    "    return [x - sum(background) for x in data]\n",
    "\n",
    "\n",
    "def process(data: BackgroundSubtractedData, param: ScaleFactor) -> Result:\n",
    "    \"\"\"Process the data, multiplying the sum by the scale factor.\"\"\"\n",
    "    return sum(data) * param\n",
    "\n",
    "\n",
    "providers = [load, clean, process, subtract_background]\n",
    "workflow = sciline.Pipeline(providers)\n",
    "workflow.visualize(Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "The `load` and `clean` providers are re-used for both the sample run and the background run.\n",
    "\n",
    "This is very common in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow[ScaleFactor] = 2.0\n",
    "workflow[Filename[Sample]] = 'file102.txt'\n",
    "workflow[Filename[Background]] = 'background.txt'\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.compute(CleanedData[Sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.compute(CleanedData[Background])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.compute(Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## How will Sciline be used at ESS?\n",
    "\n",
    "Most instruments will have **one or more** associated Sciline workflows.\n",
    "\n",
    "The workflows will be the basic interface to the data reduction software.\n",
    "\n",
    "On top of that interface we can build simpler but less flexible interfaces.\n",
    "\n",
    "- But that will take time.\n",
    "- In the early days after HC the interface to the data reduction will be mainly in the form of Sciline workflows.\n",
    "\n",
    "### What do I need to know?\n",
    "\n",
    "1. How to figure out **what quantity to compute** with the workflow.\n",
    "   - Look at the workflow graph and read on the technique package documentation page.\n",
    "3. How to figure out **what parameters are needed** to compute the target quantity.\n",
    "   - Error messages tell you what is missing, or you can look at the workflow graph.\n",
    "5. **How to set parameters** on the workflow.\n",
    "7. **How to compute** the desired quantity.\n",
    "8. How to read and **understand common error messages**.\n",
    "\n",
    "\n",
    "## There will be Sciline exercises in the training session later!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
